{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bdccdcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:51.769406Z",
     "iopub.status.busy": "2024-07-01T08:25:51.768908Z",
     "iopub.status.idle": "2024-07-01T08:25:54.427781Z",
     "shell.execute_reply": "2024-07-01T08:25:54.426597Z"
    },
    "papermill": {
     "duration": 2.671238,
     "end_time": "2024-07-01T08:25:54.430661",
     "exception": false,
     "start_time": "2024-07-01T08:25:51.759423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from nltk.probability import FreqDist\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5119fc48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:54.445849Z",
     "iopub.status.busy": "2024-07-01T08:25:54.445383Z",
     "iopub.status.idle": "2024-07-01T08:25:54.529980Z",
     "shell.execute_reply": "2024-07-01T08:25:54.528616Z"
    },
    "papermill": {
     "duration": 0.095167,
     "end_time": "2024-07-01T08:25:54.532739",
     "exception": false,
     "start_time": "2024-07-01T08:25:54.437572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Get data from json file\n",
    "with open('/kaggle/input/alqac2024/law.json', 'r', encoding='utf-8') as f:\n",
    "    law_data = json.load(f)\n",
    "\n",
    "with open('/kaggle/input/alqac2024/train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/kaggle/input/alqac2024/public_test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84367526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:54.547625Z",
     "iopub.status.busy": "2024-07-01T08:25:54.547198Z",
     "iopub.status.idle": "2024-07-01T08:25:54.562330Z",
     "shell.execute_reply": "2024-07-01T08:25:54.560643Z"
    },
    "papermill": {
     "duration": 0.026227,
     "end_time": "2024-07-01T08:25:54.565597",
     "exception": false,
     "start_time": "2024-07-01T08:25:54.539370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LexicalRetrieval(ABC):\n",
    "    def __init__(self, data: List[Dict[str, str]]):\n",
    "        # Initialize the class with a list of dictionaries containing laws and their articles.\n",
    "        self.data = data\n",
    "\n",
    "    def data2documents(self):\n",
    "        # Convert the list of laws and articles into a flat list of document texts.\n",
    "        documents = []\n",
    "        for law in self.data:\n",
    "            for article in law['articles']:\n",
    "                documents.append(article['text'])\n",
    "        return documents\n",
    "\n",
    "    def info_search(self, document: str) -> Dict[str, str]:\n",
    "        # Search for a specific document and return its associated law ID and article ID.\n",
    "        res = {}\n",
    "        for law in self.data:\n",
    "            for article in law['articles']:\n",
    "                if article['text'] == document:\n",
    "                    res['law_id'] = law['id']\n",
    "                    res['article_id'] = article['id']\n",
    "                    res[\"text\"] = article[\"text\"]\n",
    "        return res\n",
    "\n",
    "    @abstractmethod\n",
    "    def retrieve(self, query: str, top_k: int = 10) -> List[Dict[str, str]]:\n",
    "        # Abstract method to retrieve the top-k documents most relevant to the query.\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_scores(self, query_tokens: List[str]) -> np.ndarray:\n",
    "        # Abstract method to compute similarity scores for the query tokens against all documents.\n",
    "        pass\n",
    "\n",
    "    def score(self, query: str, document: str) -> float:\n",
    "        # Compute a normalized score for the similarity between the query and a specific document.\n",
    "        assert document in self.documents, \"Document not in corpus\"\n",
    "\n",
    "        query_tokens = query.split()\n",
    "        scores = self.get_scores(query_tokens)\n",
    "        scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            if doc == document:\n",
    "                return scores[i]\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d704c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:54.581265Z",
     "iopub.status.busy": "2024-07-01T08:25:54.580881Z",
     "iopub.status.idle": "2024-07-01T08:25:54.604526Z",
     "shell.execute_reply": "2024-07-01T08:25:54.603252Z"
    },
    "papermill": {
     "duration": 0.035035,
     "end_time": "2024-07-01T08:25:54.607398",
     "exception": false,
     "start_time": "2024-07-01T08:25:54.572363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QLDRetrieval(LexicalRetrieval):\n",
    "    def __init__(self, data: List[Dict[str, str]]):\n",
    "        # Initialize the class by calling the parent constructor and setting additional attributes.\n",
    "        super().__init__(data)\n",
    "        self.documents = self.data2documents()\n",
    "        self.n = 100  # A parameter for QLD scoring\n",
    "        self.alpha_d = 0.1  # Smoothing parameter for QLD scoring\n",
    "        self.epsilon = 0.00001  # Small constant to avoid division by zero\n",
    "        self.tokenized_docs, self.fdist_docs = self.preprocess_documents()  # Tokenize and compute frequency distributions for documents\n",
    "        self.collection_fdist = self.compute_collection_frequencies()  # Compute the frequency distribution for the entire collection\n",
    "\n",
    "    def preprocess_documents(self) -> List[List[str]]:\n",
    "        # Tokenize the documents and compute their frequency distributions.\n",
    "        tokenized_docs = [doc.split() for doc in self.documents]\n",
    "        fdist_docs = [FreqDist(doc) for doc in tokenized_docs]\n",
    "        return tokenized_docs, fdist_docs\n",
    "\n",
    "    def compute_collection_frequencies(self) -> FreqDist:\n",
    "        # Compute the frequency distribution of all tokens in the collection.\n",
    "        all_tokens = [token for doc in self.tokenized_docs for token in doc]\n",
    "        return FreqDist(all_tokens)\n",
    "\n",
    "    def compute_term_scores(self, query_tf: FreqDist, doc_tf: FreqDist) -> List[float]:\n",
    "        # Compute the term scores for a given query term frequency and document term frequency.\n",
    "        term_scores = []\n",
    "        for term in query_tf:\n",
    "            if term in doc_tf:\n",
    "                p_qi_d = (doc_tf[term] / len(doc_tf)) / self.alpha_d\n",
    "                p_qi_c = self.collection_fdist[term] / len(self.collection_fdist)\n",
    "                term_scores.append(math.log(p_qi_d / p_qi_c + self.epsilon))\n",
    "        return term_scores\n",
    "\n",
    "    def compute_qld_scores(self, query_tf: FreqDist, doc_tfs: List[FreqDist]) -> List[float]:\n",
    "        # Compute the QLD scores for a query against all documents.\n",
    "        scores = []\n",
    "        for doc_tf in doc_tfs:\n",
    "            term_scores = self.compute_term_scores(query_tf, doc_tf)\n",
    "            doc_score = np.sum(term_scores)\n",
    "            doc_score += self.n * math.log(self.alpha_d)\n",
    "            doc_score += np.sum([math.log(self.collection_fdist[term] / len(self.collection_fdist) + self.epsilon) for term in query_tf])\n",
    "            scores.append(doc_score)\n",
    "        return scores\n",
    "\n",
    "    def get_scores(self, query_tokens: List[str]) -> np.ndarray:\n",
    "        # Compute the similarity scores for the query tokens against all documents.\n",
    "        query_tf = FreqDist(query_tokens)\n",
    "        doc_tfs = [FreqDist(doc) for doc in self.tokenized_docs]\n",
    "        scores = self.compute_qld_scores(query_tf, doc_tfs)\n",
    "        return scores\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 10) -> List[Dict[str, str]]:\n",
    "        # Retrieve the top-k documents most relevant to the query based on QLD scores.\n",
    "        scores = self.get_scores(query.split())\n",
    "        sorted_scores = np.argsort(scores)[::-1][:top_k]\n",
    "        scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "        res = []\n",
    "        for i in sorted_scores:\n",
    "            tmp = self.info_search(self.documents[i])\n",
    "            tmp[\"qld_score\"] = scores[i]\n",
    "            res.append(tmp)\n",
    "        return res\n",
    "\n",
    "    def retrieve_all(self, query: str) -> List[Dict[str, str]]:\n",
    "        # Retrieve all documents sorted by relevance to the query based on QLD scores.\n",
    "        scores = self.get_scores(query.split())\n",
    "        sorted_scores = np.argsort(scores)[::-1]\n",
    "        scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))\n",
    "        res = []\n",
    "        for i in sorted_scores:\n",
    "            tmp = self.info_search(self.documents[i])\n",
    "            tmp[\"qld_score\"] = scores[i]\n",
    "            res.append(tmp)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f2b751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:54.622144Z",
     "iopub.status.busy": "2024-07-01T08:25:54.621720Z",
     "iopub.status.idle": "2024-07-01T08:25:54.628698Z",
     "shell.execute_reply": "2024-07-01T08:25:54.627371Z"
    },
    "papermill": {
     "duration": 0.017558,
     "end_time": "2024-07-01T08:25:54.631493",
     "exception": false,
     "start_time": "2024-07-01T08:25:54.613935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_law(law_id, article_id, data):\n",
    "    for law in data:\n",
    "        if law['id'] == law_id:\n",
    "            for article in law['articles']:\n",
    "                if article['id'] == article_id:\n",
    "                    return article['text']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd000396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:54.646448Z",
     "iopub.status.busy": "2024-07-01T08:25:54.646064Z",
     "iopub.status.idle": "2024-07-01T08:25:54.652773Z",
     "shell.execute_reply": "2024-07-01T08:25:54.651366Z"
    },
    "papermill": {
     "duration": 0.017359,
     "end_time": "2024-07-01T08:25:54.655600",
     "exception": false,
     "start_time": "2024-07-01T08:25:54.638241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_query(question_id, data):\n",
    "    for q in data:\n",
    "        if q['question_id'] == question_id:\n",
    "            return q['text']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f07a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:54.670771Z",
     "iopub.status.busy": "2024-07-01T08:25:54.670346Z",
     "iopub.status.idle": "2024-07-01T08:25:54.676971Z",
     "shell.execute_reply": "2024-07-01T08:25:54.675517Z"
    },
    "papermill": {
     "duration": 0.018299,
     "end_time": "2024-07-01T08:25:54.680472",
     "exception": false,
     "start_time": "2024-07-01T08:25:54.662173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_score(data, law_id, article_id):\n",
    "    for entry in data:\n",
    "        if entry['law_id'] == law_id and entry['article_id'] == article_id:\n",
    "            return entry['qld_score']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ae26aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:54.696918Z",
     "iopub.status.busy": "2024-07-01T08:25:54.696025Z",
     "iopub.status.idle": "2024-07-01T08:25:55.597622Z",
     "shell.execute_reply": "2024-07-01T08:25:55.596318Z"
    },
    "papermill": {
     "duration": 0.912961,
     "end_time": "2024-07-01T08:25:55.600698",
     "exception": false,
     "start_time": "2024-07-01T08:25:54.687737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qld_retrieval = QLDRetrieval(law_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0625b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:55.615885Z",
     "iopub.status.busy": "2024-07-01T08:25:55.615325Z",
     "iopub.status.idle": "2024-07-01T08:25:55.625195Z",
     "shell.execute_reply": "2024-07-01T08:25:55.623945Z"
    },
    "papermill": {
     "duration": 0.020294,
     "end_time": "2024-07-01T08:25:55.627668",
     "exception": false,
     "start_time": "2024-07-01T08:25:55.607374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_qld(data):\n",
    "    # Compute qld_score for each row and add as a new column\n",
    "    qld_scores = []               \n",
    "    scores = []\n",
    "    query = \"\"\n",
    "    for index, row in data.iterrows():\n",
    "        if query != row['query']:\n",
    "            query = row['query']\n",
    "            scores = qld_retrieval.retrieve_all(query)\n",
    "            \n",
    "        law_id = str(row['law_id'])\n",
    "        article_id = str(row['article_id'])\n",
    "\n",
    "        qld_score = find_score(scores, law_id, article_id)\n",
    "        if qld_score is None:\n",
    "            content = find_law(law_id, article_id, law_data)\n",
    "            qld_score = qld_retrieval.score(query, content)\n",
    "#         print(law_id, article_id, qld_score)\n",
    "        qld_scores.append(qld_score)\n",
    "\n",
    "    data['qld_score'] = qld_scores\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e32a7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:25:55.642829Z",
     "iopub.status.busy": "2024-07-01T08:25:55.642358Z",
     "iopub.status.idle": "2024-07-01T08:27:58.365424Z",
     "shell.execute_reply": "2024-07-01T08:27:58.363868Z"
    },
    "papermill": {
     "duration": 122.734508,
     "end_time": "2024-07-01T08:27:58.368791",
     "exception": false,
     "start_time": "2024-07-01T08:25:55.634283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path = '/kaggle/input/all-private-test-related-data-alqac-2024/bm25_bert_len_output_data_private_24_vimonot5.csv'\n",
    "\n",
    "# data = pd.read_csv(path)\n",
    "\n",
    "# data = get_qld(data)\n",
    "\n",
    "# data.to_csv('bm25_bert_len_output_data_private_24_vimonot5.csv', index=False,  encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c45d38d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:27:58.406627Z",
     "iopub.status.busy": "2024-07-01T08:27:58.406198Z",
     "iopub.status.idle": "2024-07-01T08:27:58.412121Z",
     "shell.execute_reply": "2024-07-01T08:27:58.410722Z"
    },
    "papermill": {
     "duration": 0.016505,
     "end_time": "2024-07-01T08:27:58.414781",
     "exception": false,
     "start_time": "2024-07-01T08:27:58.398276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Add qld score to each query in csv file\n",
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the path to the directory\n",
    "# directory_path = '/kaggle/input/output-concat-bm25/with label'\n",
    "\n",
    "# # List all files in the directory\n",
    "# all_files = os.listdir(directory_path)\n",
    "\n",
    "# # Filter out and process only the CSV files\n",
    "# csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "\n",
    "# # Iterate through each CSV file and read its content\n",
    "# for csv_file in csv_files:\n",
    "#     file_path = os.path.join(directory_path, csv_file)\n",
    "#     data = pd.read_csv(file_path)\n",
    "    \n",
    "#     data = get_qld(data)\n",
    "\n",
    "#     # Save the modified DataFrame back to CSV\n",
    "#     output_file_path = csv_file\n",
    "#     data.to_csv(output_file_path, index=False,  encoding='utf-8')\n",
    "    \n",
    "#     print(f\"Processed and saved {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94cde5fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:27:58.430561Z",
     "iopub.status.busy": "2024-07-01T08:27:58.430172Z",
     "iopub.status.idle": "2024-07-01T08:27:58.436402Z",
     "shell.execute_reply": "2024-07-01T08:27:58.435159Z"
    },
    "papermill": {
     "duration": 0.017238,
     "end_time": "2024-07-01T08:27:58.438877",
     "exception": false,
     "start_time": "2024-07-01T08:27:58.421639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_scores = []\n",
    "# # Get scores in train\n",
    "# for item in train_data:\n",
    "#     question_text = item[\"text\"]\n",
    "#     question_id = item['question_id']\n",
    "#     # Get top 100\n",
    "#     scores = qld_retrieval.retrieve(question_text, 100)\n",
    "#     break\n",
    "#     scores_list = []\n",
    "#     for score in scores:\n",
    "#         scores_list.append({\n",
    "#             \"qld_score\": score[\"qld_score\"],\n",
    "#             \"law_id\": score[\"law_id\"],\n",
    "#             \"article_id\": score[\"article_id\"]\n",
    "#         })\n",
    "    \n",
    "#     train_scores.append({\n",
    "#         \"question_id\": question_id,\n",
    "#         \"scores\": scores_list\n",
    "#     })\n",
    "\n",
    "# print('Train')\n",
    "# # print(train_scores[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c252c4ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:27:58.453431Z",
     "iopub.status.busy": "2024-07-01T08:27:58.453047Z",
     "iopub.status.idle": "2024-07-01T08:27:58.459262Z",
     "shell.execute_reply": "2024-07-01T08:27:58.458044Z"
    },
    "papermill": {
     "duration": 0.016636,
     "end_time": "2024-07-01T08:27:58.461902",
     "exception": false,
     "start_time": "2024-07-01T08:27:58.445266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_scores = []\n",
    "# # Get scores in test\n",
    "# for item in test_data:\n",
    "#     question_text = item[\"text\"]\n",
    "#     question_id = item['question_id']\n",
    "#     # Get top 100\n",
    "#     scores =  qld_retrieval.retrieve(question_text, 100)\n",
    "#     scores_list = []\n",
    "#     for score in scores:\n",
    "#         scores_list.append({\n",
    "#             \"qld_score\": score[\"qld_score\"],\n",
    "#             \"law_id\": score[\"law_id\"],\n",
    "#             \"article_id\": score[\"article_id\"]\n",
    "#         })\n",
    "    \n",
    "#     test_scores.append({\n",
    "#         \"question_id\": question_id,\n",
    "#         \"scores\": scores_list\n",
    "#     })\n",
    "    \n",
    "\n",
    "# print('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a31b3",
   "metadata": {
    "papermill": {
     "duration": 0.006775,
     "end_time": "2024-07-01T08:27:58.475396",
     "exception": false,
     "start_time": "2024-07-01T08:27:58.468621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74eccc5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T08:27:58.490256Z",
     "iopub.status.busy": "2024-07-01T08:27:58.489862Z",
     "iopub.status.idle": "2024-07-01T08:27:58.495339Z",
     "shell.execute_reply": "2024-07-01T08:27:58.494050Z"
    },
    "papermill": {
     "duration": 0.015829,
     "end_time": "2024-07-01T08:27:58.497952",
     "exception": false,
     "start_time": "2024-07-01T08:27:58.482123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path1= \"train_scores.json\"\n",
    "# with open(path1, \"w\", encoding=\"utf-8\") as jsonfile:\n",
    "#     json.dump(train_scores, jsonfile, ensure_ascii=False, indent=4)\n",
    "    \n",
    "# path2= \"test_scores.json\"\n",
    "# with open(path2, \"w\", encoding=\"utf-8\") as jsonfile:\n",
    "#     json.dump(test_scores, jsonfile, ensure_ascii=False, indent=4)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5187148,
     "sourceId": 8778184,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5180614,
     "sourceId": 8811336,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5279229,
     "sourceId": 8825834,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5312291,
     "sourceId": 8830398,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 131.218866,
   "end_time": "2024-07-01T08:27:59.229450",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-01T08:25:48.010584",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
