{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":8863650,"datasetId":5335297,"databundleVersionId":9023727},{"sourceType":"datasetVersion","sourceId":8910650,"datasetId":5279229,"databundleVersionId":9072015},{"sourceType":"modelInstanceVersion","sourceId":34046,"databundleVersionId":8291475,"modelInstanceId":28500},{"sourceType":"modelInstanceVersion","sourceId":33551,"databundleVersionId":8280715,"modelInstanceId":28083}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GPT Filtering","metadata":{}},{"cell_type":"code","source":"!pip install openai","metadata":{"execution":{"iopub.status.busy":"2024-07-04T13:35:20.794588Z","iopub.execute_input":"2024-07-04T13:35:20.794986Z","iopub.status.idle":"2024-07-04T13:35:38.690434Z","shell.execute_reply.started":"2024-07-04T13:35:20.794954Z","shell.execute_reply":"2024-07-04T13:35:38.689045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Once you add your API key below, make sure to not share it with anyone! The API key should remain private.\nfrom openai import OpenAI\nOPENAI_API_KEY='###PRIVATE API###' \n\nclient = OpenAI(\n  api_key=OPENAI_API_KEY,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T13:36:33.603370Z","iopub.execute_input":"2024-07-04T13:36:33.604395Z","iopub.status.idle":"2024-07-04T13:36:34.603520Z","shell.execute_reply.started":"2024-07-04T13:36:33.604351Z","shell.execute_reply":"2024-07-04T13:36:34.602302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load and process data","metadata":{}},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/input/post-process-llm/law.json\", 'r', encoding = 'utf-8') as f:\n    law_data = json.load(f)\nwith open(\"/kaggle/input/post-process-llm/private_test_TASK_1.json\", 'r', encoding = 'utf-8') as f:\n    prv = json.load(f)\n    \ncurrent_th_path = \"/kaggle/input/post-process-llm/private_24_th355_reordered_file.json\"\nwith open(current_th_path, 'r', encoding = 'utf-8') as f:\n    inferred = json.load(f)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"law_dict = {}\nfor law in law_data:\n    article_dict = {}\n    for article in law[\"articles\"]:\n        article_dict[article[\"id\"]] = article[\"text\"]\n    law_dict[law['id']] = article_dict\n    \nquestion_dict = {}\nfor question in prv:\n    question_dict[question[\"question_id\"]] = question","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:00:10.621493Z","iopub.execute_input":"2024-07-04T15:00:10.621932Z","iopub.status.idle":"2024-07-04T15:00:10.631005Z","shell.execute_reply.started":"2024-07-04T15:00:10.621900Z","shell.execute_reply":"2024-07-04T15:00:10.629645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for question in inferred:\n    question_id = question[\"question_id\"]\n    question[\"query\"] = question_dict[question_id][\"text\"]\n    for article in question[\"relevant_articles\"]:\n        law_id = article[\"law_id\"]\n        article_id = article[\"article_id\"]\n        article[\"content\"] = law_dict[law_id][article_id]\n\nwith open('gpt_postprocess.json', 'w', encoding='utf-8') as f:\n    json.dump(inferred, f, ensure_ascii=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:00:13.669858Z","iopub.execute_input":"2024-07-04T15:00:13.670324Z","iopub.status.idle":"2024-07-04T15:00:13.678100Z","shell.execute_reply.started":"2024-07-04T15:00:13.670291Z","shell.execute_reply":"2024-07-04T15:00:13.676604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GPT prompting to label article as relevant (\"1\") or redundant (\"0\")","metadata":{}},{"cell_type":"code","source":"def generate_answer(question, relevant_articles):\n    responses = []\n    for relevant_article in relevant_articles:\n        prompt = f'''Với đầu vào là câu hỏi và điều luật liên quan, bạn hãy đánh giá liệu điều luật đó có thực sự dùng để trả lời cho câu hỏi hay không? \n        Câu hỏi: \"{question}\"\n        Điều luật liên quan: \"{relevant_article[\"content\"]}\"\n        \n        Bạn chỉ được phép trả lời 1 nếu điều luật này thực sự được dùng để trả lời câu hỏi, hoặc 0 nếu điều luật đó không được dùng để trả lời câu hỏi, và bạn không được phép trả lời thêm bất cứ điều gì khác.'''\n        \n        completion = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n\n        response = str(completion.choices[0].message.content)\n        responses.append(response)\n    return responses\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:00:14.329894Z","iopub.execute_input":"2024-07-04T15:00:14.330360Z","iopub.status.idle":"2024-07-04T15:00:14.340154Z","shell.execute_reply.started":"2024-07-04T15:00:14.330326Z","shell.execute_reply":"2024-07-04T15:00:14.338547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for question in inferred:\n    if len(question[\"relevant_articles\"]) > 1:\n        responses = generate_answer(question[\"query\"], question[\"relevant_articles\"])\n        question[\"llm_responses\"] = responses\n        \nwith open('llm_responses_th355.json', 'w', encoding='utf-8') as f:\n    json.dump(inferred, f, ensure_ascii=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:00:15.317922Z","iopub.execute_input":"2024-07-04T15:00:15.318457Z","iopub.status.idle":"2024-07-04T15:00:28.909865Z","shell.execute_reply.started":"2024-07-04T15:00:15.318417Z","shell.execute_reply":"2024-07-04T15:00:28.908364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GPT Matching - Remove article responded \"0\"","metadata":{}},{"cell_type":"code","source":"import json\npath = \"/kaggle/input/llm-matching/updated_llm_responses_th2_5.json\"\nwith open(path, 'r', encoding = 'utf-8') as f:\n    inferred = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T04:05:01.952005Z","iopub.execute_input":"2024-07-05T04:05:01.952489Z","iopub.status.idle":"2024-07-05T04:05:01.979928Z","shell.execute_reply.started":"2024-07-05T04:05:01.952454Z","shell.execute_reply":"2024-07-05T04:05:01.978670Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"for question in inferred:\n    if \"llm_responses\" in question:\n        responses = question[\"llm_responses\"]\n        if \"1\" in responses:\n            for i in range(len(responses)):\n                if responses[i] == \"0\":\n                    question[\"relevant_articles\"].pop(i)\n                    i -= 1\n        del question[\"llm_responses\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-05T04:05:02.154928Z","iopub.execute_input":"2024-07-05T04:05:02.155471Z","iopub.status.idle":"2024-07-05T04:05:02.163319Z","shell.execute_reply.started":"2024-07-05T04:05:02.155436Z","shell.execute_reply":"2024-07-05T04:05:02.161928Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"with open('postprocessed_gpt.json', 'w', encoding='utf-8') as f:\n    json.dump(inferred, f, ensure_ascii=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T04:05:02.362007Z","iopub.execute_input":"2024-07-05T04:05:02.362514Z","iopub.status.idle":"2024-07-05T04:05:02.371999Z","shell.execute_reply.started":"2024-07-05T04:05:02.362480Z","shell.execute_reply":"2024-07-05T04:05:02.370302Z"},"trusted":true},"execution_count":33,"outputs":[]}]}